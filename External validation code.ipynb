{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86dd2e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Binary model: Random Forest\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Training Binary model: Logistic Regression\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Training Binary model: SVM\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Training Binary model: MLP\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Training LSTM Binary Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dipra\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Binary Classification External Validation Results:\n",
      "Model: Random Forest\n",
      "Accuracy: 0.7152\n",
      "Precision: 0.5326\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.6950\n",
      "\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.6954\n",
      "Precision: 0.5158\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.6806\n",
      "\n",
      "Model: Naive Bayes\n",
      "Accuracy: 0.7483\n",
      "Precision: 0.5632\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.7206\n",
      "\n",
      "Model: SVM\n",
      "Accuracy: 0.3245\n",
      "Precision: 0.3245\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.4900\n",
      "\n",
      "Model: MLP\n",
      "Accuracy: 0.7152\n",
      "Precision: 0.5333\n",
      "Recall: 0.9796\n",
      "F1-Score: 0.6906\n",
      "\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step\n",
      "Model: LSTM\n",
      "Accuracy: 0.4305\n",
      "Precision: 0.3566\n",
      "Recall: 0.9388\n",
      "F1-Score: 0.5169\n",
      "\n",
      "Training Multiclass model: Decision Tree\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Training Multiclass model: KNN\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Training Multiclass model: LightGBM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 378\n",
      "[LightGBM] [Info] Number of data points in the train set: 750, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -0.450462\n",
      "[LightGBM] [Info] Start training from score -1.110685\n",
      "[LightGBM] [Info] Start training from score -3.401197\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training Multiclass model: XGBoost\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dipra\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [16:32:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Multiclass model: MLP\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Training CNN Multiclass Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dipra\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multiclass Classification External Validation Results:\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.4768\n",
      "Precision (weighted): 0.7582\n",
      "Recall (weighted): 0.4768\n",
      "F1-Score (weighted): 0.5319\n",
      "\n",
      "Model: KNN\n",
      "Accuracy: 0.5828\n",
      "Precision (weighted): 0.6393\n",
      "Recall (weighted): 0.5828\n",
      "F1-Score (weighted): 0.6066\n",
      "\n",
      "Model: LightGBM\n",
      "Accuracy: 0.2583\n",
      "Precision (weighted): 0.4674\n",
      "Recall (weighted): 0.2583\n",
      "F1-Score (weighted): 0.3220\n",
      "\n",
      "Model: XGBoost\n",
      "Accuracy: 0.4967\n",
      "Precision (weighted): 0.5903\n",
      "Recall (weighted): 0.4967\n",
      "F1-Score (weighted): 0.5324\n",
      "\n",
      "Model: MLP\n",
      "Accuracy: 0.5166\n",
      "Precision (weighted): 0.5967\n",
      "Recall (weighted): 0.5166\n",
      "F1-Score (weighted): 0.5469\n",
      "\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Model: CNN\n",
      "Accuracy: 0.5894\n",
      "Precision (weighted): 0.6133\n",
      "Recall (weighted): 0.5894\n",
      "F1-Score (weighted): 0.5982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# For LSTM and CNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# === Step 1: Load your training and testing datasets ===\n",
    "df_train = pd.read_csv('processed_train.csv')\n",
    "df_test = pd.read_csv('processed_test.csv')\n",
    "\n",
    "# === Step 2: Fix Academic_Level ===\n",
    "def map_academic_level(val):\n",
    "    if str(val).lower() in ['undergraduate', 'graduate', 'high school', 'student', 'college']:\n",
    "        return 'Student'\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "df_train['Academic_Level'] = df_train['Academic_Level'].apply(map_academic_level)\n",
    "df_test['Academic_Level'] = df_test['Academic_Level'].apply(map_academic_level)\n",
    "\n",
    "# === Step 3: Fix Country column by converting all test countries to \"Bangladesh\" ===\n",
    "df_test['Country'] = 'Bangladesh'\n",
    "df_test['Most_Used_Platform'] = 'Facebook'\n",
    "# === Step 4: Label Encoding categorical columns based on train data only ===\n",
    "label_cols = ['Gender', 'Academic_Level', 'Country', 'Most_Used_Platform', 'Affects_Academic_Performance', 'Relationship_Status']\n",
    "label_encoders = {}\n",
    "\n",
    "for col in label_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_train[col] = le.fit_transform(df_train[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "    df_test[col] = le.transform(df_test[col].astype(str))\n",
    "\n",
    "# === Step 5: Create binary and multiclass target labels ===\n",
    "df_train['Mental_Health_Binary'] = df_train['Mental_Health_Score'].apply(lambda x: 1 if x <= 5 else 0)\n",
    "df_test['Mental_Health_Binary'] = df_test['Mental_Health_Score'].apply(lambda x: 1 if x <= 5 else 0)\n",
    "\n",
    "def multi_class_label(score):\n",
    "    if score <= 4:\n",
    "        return 0\n",
    "    elif score <= 7:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df_train['Mental_Health_Multiclass'] = df_train['Mental_Health_Score'].apply(multi_class_label)\n",
    "df_test['Mental_Health_Multiclass'] = df_test['Mental_Health_Score'].apply(multi_class_label)\n",
    "\n",
    "# === Step 6: Feature Scaling for continuous features ===\n",
    "cont_cols = ['Avg_Daily_Usage_Hours', 'Sleep_Hours_Per_Night', 'Addicted_Score']\n",
    "scaler = StandardScaler()\n",
    "df_train[cont_cols] = scaler.fit_transform(df_train[cont_cols])\n",
    "df_test[cont_cols] = scaler.transform(df_test[cont_cols])\n",
    "\n",
    "# === Step 7: Split features and targets ===\n",
    "X_train = df_train.drop(columns=['Mental_Health_Score', 'Mental_Health_Binary', 'Mental_Health_Multiclass'])\n",
    "y_train_binary = df_train['Mental_Health_Binary']\n",
    "y_train_multi = df_train['Mental_Health_Multiclass']\n",
    "\n",
    "X_test = df_test.drop(columns=['Mental_Health_Score', 'Mental_Health_Binary', 'Mental_Health_Multiclass'])\n",
    "y_test_binary = df_test['Mental_Health_Binary']\n",
    "y_test_multi = df_test['Mental_Health_Multiclass']\n",
    "\n",
    "# === Step 8: Define models and hyperparameters ===\n",
    "binary_models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"MLP\": MLPClassifier(max_iter=300),\n",
    "    # LSTM separately below\n",
    "}\n",
    "\n",
    "binary_param_grid = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10],\n",
    "        'min_samples_split': [2, 5],\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'solver': ['liblinear'],\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "    },\n",
    "    'MLP': {\n",
    "        'hidden_layer_sizes': [(64,), (64, 32)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'alpha': [0.0001, 0.001],\n",
    "    }\n",
    "}\n",
    "\n",
    "multi_models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"LightGBM\": lgb.LGBMClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "    \"MLP\": MLPClassifier(max_iter=300),\n",
    "    # CNN separately below\n",
    "}\n",
    "\n",
    "multi_param_grid = {\n",
    "    'Decision Tree': {\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5],\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': [3, 5, 7],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan'],\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'num_leaves': [31, 64],\n",
    "        'learning_rate': [0.1, 0.01],\n",
    "        'n_estimators': [100, 200],\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'max_depth': [3, 5],\n",
    "        'learning_rate': [0.1, 0.01],\n",
    "        'n_estimators': [100, 200],\n",
    "    },\n",
    "    'MLP': {\n",
    "        'hidden_layer_sizes': [(64,), (128,)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'alpha': [0.0001, 0.001],\n",
    "    }\n",
    "}\n",
    "\n",
    "# === Step 9: Train Binary models with GridSearchCV (skip Naive Bayes and LSTM) ===\n",
    "binary_best_models = {}\n",
    "for model_name, model in binary_models.items():\n",
    "    if model_name == \"Naive Bayes\":\n",
    "        model.fit(X_train, y_train_binary)\n",
    "        binary_best_models[model_name] = model\n",
    "        continue\n",
    "    print(f\"Training Binary model: {model_name}\")\n",
    "    grid_search = GridSearchCV(model, binary_param_grid[model_name], cv=5, n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train, y_train_binary)\n",
    "    binary_best_models[model_name] = grid_search.best_estimator_\n",
    "\n",
    "# === Train LSTM binary model separately ===\n",
    "def create_lstm_model_binary(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=input_shape, return_sequences=True),\n",
    "        Dropout(0.5),\n",
    "        LSTM(64),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "print(\"Training LSTM Binary Model...\")\n",
    "X_train_lstm = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "lstm_model_binary = create_lstm_model_binary((1, X_train.shape[1]))\n",
    "lstm_model_binary.fit(X_train_lstm, y_train_binary, epochs=10, batch_size=32, verbose=0)\n",
    "binary_best_models[\"LSTM\"] = lstm_model_binary\n",
    "\n",
    "# === Step 10: Evaluate binary models on external test dataset ===\n",
    "print(\"\\nBinary Classification External Validation Results:\")\n",
    "for model_name, model in binary_best_models.items():\n",
    "    if model_name == \"LSTM\":\n",
    "        X_test_lstm = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "        y_pred_prob = model.predict(X_test_lstm)\n",
    "        y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test_binary, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test_binary, y_pred, zero_division=0):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test_binary, y_pred, zero_division=0):.4f}\")\n",
    "    print(f\"F1-Score: {f1_score(y_test_binary, y_pred, zero_division=0):.4f}\\n\")\n",
    "\n",
    "# === Step 11: Train Multiclass models with GridSearchCV (skip CNN) ===\n",
    "multi_best_models = {}\n",
    "for model_name, model in multi_models.items():\n",
    "    print(f\"Training Multiclass model: {model_name}\")\n",
    "    grid_search = GridSearchCV(model, multi_param_grid[model_name], cv=5, n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train, y_train_multi)\n",
    "    multi_best_models[model_name] = grid_search.best_estimator_\n",
    "\n",
    "# === Train CNN multiclass model separately ===\n",
    "def create_cnn_model_multiclass(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(32, 3, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "print(\"Training CNN Multiclass Model...\")\n",
    "X_train_cnn = np.reshape(X_train.values, (X_train.shape[0], X_train.shape[1], 1))\n",
    "y_train_cnn = to_categorical(y_train_multi, num_classes=3)\n",
    "cnn_model_multiclass = create_cnn_model_multiclass((X_train.shape[1], 1))\n",
    "cnn_model_multiclass.fit(X_train_cnn, y_train_cnn, epochs=10, batch_size=32, verbose=0)\n",
    "multi_best_models[\"CNN\"] = cnn_model_multiclass\n",
    "\n",
    "# === Step 12: Evaluate multiclass models on external test dataset ===\n",
    "print(\"\\nMulticlass Classification External Validation Results:\")\n",
    "for model_name, model in multi_best_models.items():\n",
    "    if model_name == \"CNN\":\n",
    "        X_test_cnn = np.reshape(X_test.values, (X_test.shape[0], X_test.shape[1], 1))\n",
    "        y_pred_prob = model.predict(X_test_cnn)\n",
    "        y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test_multi, y_pred):.4f}\")\n",
    "    print(f\"Precision (weighted): {precision_score(y_test_multi, y_pred, average='weighted', zero_division=0):.4f}\")\n",
    "    print(f\"Recall (weighted): {recall_score(y_test_multi, y_pred, average='weighted', zero_division=0):.4f}\")\n",
    "    print(f\"F1-Score (weighted): {f1_score(y_test_multi, y_pred, average='weighted', zero_division=0):.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5dcfa2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Binary Classification Results:\n",
      "              Model  F1-Score  Accuracy   Recall  Precision\n",
      "        Naive Bayes  0.720588  0.748344 1.000000   0.563218\n",
      "      Random Forest  0.695035  0.715232 1.000000   0.532609\n",
      "                MLP  0.690647  0.715232 0.979592   0.533333\n",
      "Logistic Regression  0.680556  0.695364 1.000000   0.515789\n",
      "               LSTM  0.516854  0.430464 0.938776   0.356589\n",
      "                SVM  0.490000  0.324503 1.000000   0.324503\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "binary_results = {}\n",
    "\n",
    "for model_name, model in binary_best_models.items():\n",
    "    if model_name == \"LSTM\":\n",
    "        X_test_lstm = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "        y_pred_prob = model.predict(X_test_lstm)\n",
    "        y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    binary_results[model_name] = {\n",
    "        'accuracy': accuracy_score(y_test_binary, y_pred),\n",
    "        'precision': precision_score(y_test_binary, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_test_binary, y_pred, zero_division=0),\n",
    "        'f1_score': f1_score(y_test_binary, y_pred, zero_division=0)\n",
    "    }\n",
    "\n",
    "binary_result_table = pd.DataFrame([\n",
    "    [model,\n",
    "     round(metrics['f1_score'], 6),\n",
    "     round(metrics['accuracy'], 6),\n",
    "     round(metrics['recall'], 6),\n",
    "     round(metrics['precision'], 6)]\n",
    "    for model, metrics in binary_results.items()\n",
    "], columns=[\"Model\", \"F1-Score\", \"Accuracy\", \"Recall\", \"Precision\"])\n",
    "\n",
    "binary_result_table = binary_result_table.sort_values(by=\"F1-Score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Binary Classification Results:\")\n",
    "print(binary_result_table.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61048845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\n",
      "Multiclass Classification Results:\n",
      "        Model  F1-Score  Accuracy   Recall  Precision\n",
      "          KNN  0.606576  0.582781 0.582781   0.639336\n",
      "          CNN  0.598189  0.589404 0.589404   0.613304\n",
      "          MLP  0.546873  0.516556 0.516556   0.596707\n",
      "      XGBoost  0.532352  0.496689 0.496689   0.590321\n",
      "Decision Tree  0.531905  0.476821 0.476821   0.758245\n",
      "     LightGBM  0.322037  0.258278 0.258278   0.467399\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "multi_results = {}\n",
    "\n",
    "for model_name, model in multi_best_models.items():\n",
    "    if model_name == \"CNN\":\n",
    "        X_test_cnn = np.reshape(X_test.values, (X_test.shape[0], X_test.shape[1], 1))\n",
    "        y_pred_prob = model.predict(X_test_cnn)\n",
    "        y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    multi_results[model_name] = {\n",
    "        'accuracy': accuracy_score(y_test_multi, y_pred),\n",
    "        'precision': precision_score(y_test_multi, y_pred, average='weighted', zero_division=0),\n",
    "        'recall': recall_score(y_test_multi, y_pred, average='weighted', zero_division=0),\n",
    "        'f1_score': f1_score(y_test_multi, y_pred, average='weighted', zero_division=0)\n",
    "    }\n",
    "\n",
    "multi_result_table = pd.DataFrame([\n",
    "    [model,\n",
    "     round(metrics['f1_score'], 6),\n",
    "     round(metrics['accuracy'], 6),\n",
    "     round(metrics['recall'], 6),\n",
    "     round(metrics['precision'], 6)]\n",
    "    for model, metrics in multi_results.items()\n",
    "], columns=[\"Model\", \"F1-Score\", \"Accuracy\", \"Recall\", \"Precision\"])\n",
    "\n",
    "multi_result_table = multi_result_table.sort_values(by=\"F1-Score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nMulticlass Classification Results:\")\n",
    "print(multi_result_table.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
